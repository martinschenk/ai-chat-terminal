# AI Chat Terminal

Lokaler Chat im Terminal mit automatischem Datenschutz fÃ¼r sensible Daten.

[![Version](https://img.shields.io/badge/version-6.2.0-blue.svg)](https://github.com/martinschenk/ai-chat-terminal)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Platform](https://img.shields.io/badge/platform-macOS-lightgrey.svg)](https://github.com/martinschenk/ai-chat-terminal)

## Was ist AI Chat Terminal?

Ein Chat-System das im Terminal lÃ¤uft und automatisch entscheidet: Sensible Eingaben bleiben lokal in einer Vektordatenbank, Ã¶ffentliche Fragen gehen an OpenAI.

**Funktionsweise:**
- Eingabe mit privaten Daten (API Keys, PasswÃ¶rter) â†’ Lokale Speicherung
- Ã–ffentliche Fragen (z.B. "Hauptstadt Frankreich?") â†’ OpenAI
- Abfrage privater Daten â†’ Lokale Datenbank (nie Cloud)

### Datenfluss: Eingabe & Speicherung

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Eingabe: "Meine API Key ist sk-abc123..."    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Privacy Classifier   â”‚ â† KI entscheidet automatisch
          â”‚   (lokal auf Mac)    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“                       â†“
   ğŸ”’ SENSIBEL              ğŸŒ Ã–FFENTLICH
   (lokal speichern)        (â†’ OpenAI)
         â†“                       â†“
   [Vektordatenbank]        [OpenAI GPT-4]
   ~/.aichat/memory.db
```

### Datenfluss: Abruf privater Daten

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frage: "Was ist meine API Key?"   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Erkennt: Private     â”‚
    â”‚ Daten-Abfrage       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
       ğŸ”’ Lokale DB
       â”œâ”€ Semantische Suche in Vektordatenbank
       â””â”€ Gibt zurÃ¼ck: "sk-abc123..."

    âŒ Nie an OpenAI gesendet!
```

---

## Quick Start

**Schritt 1: Installation**
```bash
curl -fsSL https://raw.githubusercontent.com/martinschenk/ai-chat-terminal/main/install.sh | zsh
```

**Schritt 2: Shell neu laden**
```bash
source ~/.zshrc
```

**Schritt 3: Starten**
```bash
chat
```

---

## Requirements

| | Minimum | Empfohlen |
|---|---|---|
| **macOS** | Catalina 10.15+ | Monterey 12+ |
| **RAM** | 8 GB | 16 GB |
| **Speicher** | 5 GB frei | 10 GB frei |
| **Prozessor** | Intel 2015+ | Apple Silicon M1+ |

### KompatibilitÃ¤t

- âœ… **M1/M2/M3 Mac mit 16+ GB RAM** â†’ Alle Modelle empfohlen
- âœ… **Intel Mac mit 16 GB RAM** â†’ Alle Modelle funktionieren
- âš ï¸ **8 GB RAM** â†’ Basis-Modelle (ohne Phi-3)
- âŒ **< macOS Catalina** â†’ Nicht unterstÃ¼tzt (Linux/Windows: Coming soon)

---

## Beispiele

### Sensible Daten (bleiben lokal)

```bash
Du: Meine Kreditkarte ist 4532-1234-5678-9012
AI: [Gespeichert in lokaler DB] ğŸ”’

Du: API Key ist sk-proj-abc123def456
AI: [Gespeichert] ğŸ”’

Du: Was war meine Kreditkarte?
AI: 4532-1234-5678-9012 [Aus lokaler DB] ğŸ”’
```

### Ã–ffentliche Fragen (an OpenAI)

```bash
Du: Hauptstadt von Frankreich?
AI: Paris [OpenAI GPT-4] ğŸŒ

Du: ErklÃ¤re Quantenphysik
AI: [Antwort von OpenAI] ğŸŒ
```

---

## Features

- **Automatischer Datenschutz**: KI-basierte Klassifizierung
- **19 Sprachen**: DE, EN, ES, FR, IT, CA, ZH, HI, etc.
- **Vektordatenbank**: SQLite mit semantischer Suche
- **Konfigurierbar**: `/config` MenÃ¼ fÃ¼r alle Einstellungen
- **OpenAI Integration**: GPT-4, GPT-4o, GPT-4o-mini

---

## Installation Details

### Was wird wo installiert?

**Lokal (~/.aichat/)**
- Scripts, Config, Chat-Historie
- Deine privaten Daten in Vektordatenbank
- Nur von diesem Tool genutzt

**Global (shared)**
- AI-Modelle (HuggingFace Cache)
- Python-Pakete (pip --user)
- Kann von anderen Apps genutzt werden

### Intelligente Model-Auswahl

Das Installer-Script analysiert deinen Mac und empfiehlt:

| Dein Mac | Empfehlung |
|----------|-----------|
| 16+ GB RAM | Presidio âœ… + Phi-3 âœ… |
| 8-16 GB RAM | Presidio âœ…, Phi-3 optional |
| <8 GB RAM | Nur Basis-Modelle |

**Beispiel-Output bei 16 GB RAM:**
```
ğŸ’¬ Warum empfohlen fÃ¼r dich?
   Dein Mac hat 16 GB RAM - perfekt fÃ¼r Presidio!
   SchÃ¼tzt Kreditkarten, API-Keys, PasswÃ¶rter.
```

---

## Technische Details

### Komponenten

| Komponente | Modell | GrÃ¶ÃŸe | Zweck |
|------------|--------|-------|-------|
| Privacy Classifier | all-MiniLM-L6-v2 | 22 MB | Routing-Entscheidung |
| Memory System | multilingual-e5-base | 278 MB | Semantische Suche |
| PII Detection | Microsoft Presidio | 350 MB | Erkennung sensibler Daten |
| Response Generator | Phi-3 via Ollama | 2.3 GB | NatÃ¼rliche Antworten |

### Privacy Layers

1. **PII Detector**: Erkennt konkrete Datentypen (Kreditkarten, API-Keys)
2. **Semantic Classifier**: Versteht Kontext (SENSITIVE/PUBLIC)
3. **Vector Database**: Lokale Speicherung mit Embeddings

---

## Konfiguration

```bash
chat           # Starten
/config        # Einstellungen
```

**VerfÃ¼gbare Optionen:**
- Sprache wÃ¤hlen (19 verfÃ¼gbar)
- OpenAI Modell Ã¤ndern
- Privacy-Level anpassen
- Modelle nachtrÃ¤glich installieren/entfernen
- Context-Window konfigurieren

---

## Deinstallation

**Im Chat:**
```bash
chat
/config
â†’ [12] VollstÃ¤ndig deinstallieren
```

**Manuell:**
```bash
rm -rf ~/.aichat
```

*Hinweis: Globale Modelle bleiben erhalten (kÃ¶nnen von anderen Apps genutzt werden)*

---

## FAQ

**Q: Sind meine Daten wirklich privat?**
A: Ja. Sensible Daten werden nie an OpenAI gesendet. PrÃ¼fe den Indikator: ğŸ”’ = lokal, ğŸŒ = OpenAI

**Q: Funktioniert es offline?**
A: Lokale Features ja. OpenAI-Abfragen benÃ¶tigen Internet.

**Q: Wie funktioniert die Erkennung?**
A: Dreistufig: PII-Detector â†’ Semantic Classifier â†’ Routing

**Q: Kann ich andere Modelle nutzen?**
A: Aktuell nur OpenAI. Support fÃ¼r Claude/Gemini: In Planung

**Q: Linux/Windows Support?**
A: Aktuell nur macOS. Linux: Geplant fÃ¼r v7.0

---

## Lizenz

MIT License - siehe [LICENSE](LICENSE)

**Built with â¤ï¸ for Privacy**
